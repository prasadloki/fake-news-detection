{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RlDEEwGGxqb"
   },
   "source": [
    "## **Step 1: Load & Preprocess the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "7f9RG2IxFBKm",
    "outputId": "6e4e9cff-5c78-4929-ec6b-db699de6e959"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44898, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ben Stein Calls Out 9th Circuit Court: Committ...</td>\n",
       "      <td>21st Century Wire says Ben Stein, reputable pr...</td>\n",
       "      <td>US_News</td>\n",
       "      <td>February 13, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trump drops Steve Bannon from National Securit...</td>\n",
       "      <td>WASHINGTON (Reuters) - U.S. President Donald T...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>April 5, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Puerto Rico expects U.S. to lift Jones Act shi...</td>\n",
       "      <td>(Reuters) - Puerto Rico Governor Ricardo Rosse...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>September 27, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OOPS: Trump Just Accidentally Confirmed He Le...</td>\n",
       "      <td>On Monday, Donald Trump once again embarrassed...</td>\n",
       "      <td>News</td>\n",
       "      <td>May 22, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donald Trump heads for Scotland to reopen a go...</td>\n",
       "      <td>GLASGOW, Scotland (Reuters) - Most U.S. presid...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>June 24, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Ben Stein Calls Out 9th Circuit Court: Committ...   \n",
       "1  Trump drops Steve Bannon from National Securit...   \n",
       "2  Puerto Rico expects U.S. to lift Jones Act shi...   \n",
       "3   OOPS: Trump Just Accidentally Confirmed He Le...   \n",
       "4  Donald Trump heads for Scotland to reopen a go...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  21st Century Wire says Ben Stein, reputable pr...       US_News   \n",
       "1  WASHINGTON (Reuters) - U.S. President Donald T...  politicsNews   \n",
       "2  (Reuters) - Puerto Rico Governor Ricardo Rosse...  politicsNews   \n",
       "3  On Monday, Donald Trump once again embarrassed...          News   \n",
       "4  GLASGOW, Scotland (Reuters) - Most U.S. presid...  politicsNews   \n",
       "\n",
       "                  date  label  \n",
       "0    February 13, 2017      1  \n",
       "1       April 5, 2017       0  \n",
       "2  September 27, 2017       0  \n",
       "3         May 22, 2017      1  \n",
       "4       June 24, 2016       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "df_fake = pd.read_csv('/Users/prasadbodduboina/Documents/untitled folder/Fake.csv')\n",
    "df_true = pd.read_csv('/Users/prasadbodduboina/Documents/untitled folder/True.csv')\n",
    "\n",
    "# Add labels\n",
    "df_fake[\"label\"] = 1\n",
    "df_true[\"label\"] = 0\n",
    "\n",
    "# Combine datasets\n",
    "df = pd.concat([df_fake, df_true], ignore_index=True)\n",
    "\n",
    "# Shuffle the data\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# View the data\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FwRyX_hkG-US"
   },
   "source": [
    "# Step 2: Text Cleaning + TF-IDF Feature Extraction\n",
    "\n",
    "We'll:\n",
    "\n",
    "Remove punctuation, stopwords, etc.\n",
    "\n",
    "Convert text to lowercase\n",
    "\n",
    "Extract features using TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LjsXCeE5GXVi"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Clean text function\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)                      # remove [text]\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)        # remove links\n",
    "    text = re.sub(r'<.*?>+', '', text)                       # remove HTML tags\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)  # remove punctuation\n",
    "    text = re.sub(r'\\n', '', text)                           # remove newlines\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)                     # remove numbers/words with digits\n",
    "    return text\n",
    "\n",
    "# Apply cleaning to the 'text' column\n",
    "df['text'] = df['title'] + \" \" + df['text']  # Combine title + content\n",
    "df['text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# Split data\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-egd8KGlHgQZ"
   },
   "source": [
    "# Step 3: Train the Model\n",
    "Letâ€™s use Logistic Regression, which is simple, fast, and works very well for text classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0j0Wju0FHi1x",
    "outputId": "9858af0f-cc08-4727-d0d7-e16121b6ce17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.984521158129176\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      4270\n",
      "           1       0.99      0.98      0.99      4710\n",
      "\n",
      "    accuracy                           0.98      8980\n",
      "   macro avg       0.98      0.98      0.98      8980\n",
      "weighted avg       0.98      0.98      0.98      8980\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4219   51]\n",
      " [  88 4622]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8gRrrl5H2Rp"
   },
   "source": [
    "# Step 5: Save Model and Vectorizer\n",
    "Weâ€™ll now save:\n",
    "\n",
    "The trained Logistic Regression model\n",
    "\n",
    "The TF-IDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r7uqCI_zH1fQ",
    "outputId": "dd58840f-af48-4325-fef5-5d06ed94971c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Create a models directory\n",
    "import os\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# Save model and vectorizer\n",
    "joblib.dump(model, \"models/fake_news_model.pkl\")\n",
    "joblib.dump(vectorizer, \"models/tfidf_vectorizer.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38NC5qB2I9ui",
    "outputId": "0b378834-8cb0-415d-c302-3b4bf9e43f53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Create folder\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# Save trained model and vectorizer\n",
    "joblib.dump(model, \"models/fake_news_model.pkl\")\n",
    "joblib.dump(vectorizer, \"models/tfidf_vectorizer.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qGdwO3xrJKlk",
    "outputId": "ef37f06d-5ee8-4556-c8e9-196967cb0d2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Make sure model and vectorizer are both saved\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, \"models/fake_news_model.pkl\")  # ðŸ‘ˆ This is the missing step\n",
    "\n",
    "# (Optional: Save vectorizer again, in case it changed)\n",
    "joblib.dump(vectorizer, \"models/tfidf_vectorizer.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9B2W0zwJSCx",
    "outputId": "6f36b281-e5d2-499f-ccd3-dba5b27baaa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ['tfidf_vectorizer.pkl', 'fake_news_model.pkl']\n"
     ]
    }
   ],
   "source": [
    "print(\"Saved:\", os.listdir(\"models\"))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
